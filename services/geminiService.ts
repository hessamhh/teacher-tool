// FIX: Import GenerateContentResponse to correctly type API call results.
import { GoogleGenAI, Modality, Type, GenerateContentResponse } from '@google/genai';
import type { ImageFile, ServiceResponse, ObjectTransform } from '../types';

export const ai = new GoogleGenAI({ apiKey: process.env.API_KEY! });

const retry = async <T>(fn: () => Promise<T>, retries = 3, delay = 1000): Promise<T> => {
  try {
    return await fn();
  } catch (error) {
    if (retries > 0) {
      console.warn(`Retrying... attempts left: ${retries}`);
      await new Promise(res => setTimeout(res, delay));
      return retry(fn, retries - 1, delay * 2); // Exponential backoff
    } else {
      throw error;
    }
  }
};

const formatError = (error: unknown, context: string): string => {
    console.error(`Error during ${context}:`, error);
    if (error instanceof Error) {
        return `Failed during ${context}: ${error.message}`;
    }
    return `An unknown error occurred during ${context}.`;
};

const processImageResponse = (response: GenerateContentResponse, originalName: string, namePrefix: string): ImageFile => {
    const candidate = response?.candidates?.[0];

    if (!candidate) {
        const promptFeedback = response?.promptFeedback;
        if (promptFeedback?.blockReason) {
            throw new Error(`Request was blocked: ${promptFeedback.blockReason}.`);
        }
        throw new Error('No candidates were returned by the model. The request may have been blocked or filtered.');
    }

    if (candidate.finishReason && candidate.finishReason !== 'STOP') {
         if (candidate.finishReason === 'SAFETY') {
             throw new Error(`Image generation failed due to safety policies. Please try a different image or prompt.`);
         }
         throw new Error(`Image generation stopped unexpectedly with reason: ${candidate.finishReason}.`);
    }

    const parts = candidate.content?.parts;

    if (!parts || parts.length === 0) {
        throw new Error('Model did not return any content parts.');
    }

    for (const part of parts) {
        if (part.inlineData) {
            return {
                base64: `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`,
                mimeType: part.inlineData.mimeType,
                name: `${namePrefix}-${originalName}`,
            };
        }
    }
    throw new Error('No image was generated by the model.');
}

export const removePeopleFromImage = async (image: ImageFile): Promise<ServiceResponse<ImageFile>> => {
    try {
      const prompt = `
        TASK: Depopulate Scene & Reconstruct Background.
        
        GOAL: Generate a new image that shows ONLY the background environment and furniture from the original image. Any people or animals present in the original image MUST NOT be in the new image.
        
        CRITICAL INSTRUCTIONS:
        1.  **Re-create the scene WITHOUT people/animals:** Imagine you are standing in the same room, but it is empty of any living beings. Your task is to generate what that scene would look like.
        2.  **Intelligently reconstruct hidden areas:** The areas that were previously blocked by the person/animal must be realistically filled in. The reconstruction should seamlessly blend with the visible parts of the room. For example, if a person was sitting on a couch, you must draw the rest of the couch.
        3.  **Preserve the original environment:** The furniture, objects, lighting, and perspective of the room must be perfectly maintained. Do not add, remove, or change any objects other than the people/animals.
        4.  **Output:** The final image must be a high-quality, photorealistic image of the empty room.
      `;
  
      const response: GenerateContentResponse = await retry(() => ai.models.generateContent({
        model: 'gemini-2.5-flash-image',
        contents: { parts: [
          {
            inlineData: {
              data: image.base64.split(',')[1],
              mimeType: image.mimeType,
            },
          },
          { text: prompt },
        ]},
        config: {
          responseModalities: [Modality.IMAGE],
        },
      }));
  
      const cleanedImage = processImageResponse(response, image.name, 'cleaned');
      return { data: cleanedImage, error: null };
    } catch (error) {
      return { data: null, error: formatError(error, 'removing people from image') };
    }
  };

export const extendImageTo16x9 = async (image: ImageFile): Promise<ServiceResponse<ImageFile>> => {
  try {
    const response: GenerateContentResponse = await retry(() => ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: { parts: [
        {
          inlineData: {
            data: image.base64.split(',')[1],
            mimeType: image.mimeType,
          },
        },
        { text: 'Extend this image to a 16:9 aspect ratio. Intelligently fill in the new areas to seamlessly continue the existing scene. Do not change the content of the original image area. The result should be a natural continuation of the room.' },
      ]},
      config: {
        responseModalities: [Modality.IMAGE],
      },
    }));
    const extendedImage = processImageResponse(response, image.name, 'extended');
    return { data: extendedImage, error: null };
  } catch (error) {
    return { data: null, error: formatError(error, 'image extension') };
  }
};


export const inpaintImage = async (originalImage: ImageFile, mask: ImageFile, prompt: string): Promise<ServiceResponse<ImageFile>> => {
    try {
        const response: GenerateContentResponse = await retry(() => ai.models.generateContent({
          model: 'gemini-2.5-flash-image',
          contents: { parts: [
            { // The original image
              inlineData: {
                data: originalImage.base64.split(',')[1],
                mimeType: originalImage.mimeType,
              },
            },
            { // The text prompt
              text: prompt,
            },
            { // The mask
              inlineData: {
                data: mask.base64.split(',')[1],
                mimeType: mask.mimeType,
              }
            }
          ]},
          config: {
            responseModalities: [Modality.IMAGE],
          },
        }));

        const inpaintedImage = processImageResponse(response, originalImage.name, 'inpainted');
        return { data: inpaintedImage, error: null };

    } catch (error) {
        return { data: null, error: formatError(error, 'inpainting') };
    }
};

export const getRefinementSuggestions = async (theme: string): Promise<ServiceResponse<string[]>> => {
    try {
        const prompt = `Based on the theme "${theme}", generate 5 short, creative refinement suggestions for a room environment. The suggestions should be things you could add, change, or enhance. For example, if the theme is "Enchanted Forest", suggestions could be "Add glowing mushrooms", "Make it nighttime", or "Add a waterfall". Respond with ONLY a valid JSON array of strings. Example: ["suggestion 1", "suggestion 2", "suggestion 3", "suggestion 4", "suggestion 5"]`;

        const response: GenerateContentResponse = await retry(() => ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: { parts: [{ text: prompt }] },
            config: {
                responseMimeType: 'application/json',
                responseSchema: {
                    type: Type.ARRAY,
                    items: { type: Type.STRING }
                }
            }
        }));
        
        const jsonString = response.text;
        const result = JSON.parse(jsonString);
        
        if (Array.isArray(result) && result.every(item => typeof item === 'string')) {
            return { data: result, error: null };
        } else {
            console.error("Invalid suggestion format received from model:", result);
            return { data: null, error: "Received invalid format for suggestions." };
        }

    } catch (error) {
        return { data: null, error: formatError(error, 'getting refinement suggestions') };
    }
};

const getFidelityPrompt = (fidelity: number): string => {
    if (fidelity > 80) {
        return `CRITICAL TASK: Regenerate the 'transformed' image to be EXTREMELY faithful to the 'original room'.
        
        HIGHEST PRIORITY: The output MUST contain the exact furniture, objects, and layout from the 'original room'.
        STYLE: Use the 'transformed image' ONLY as a style, color, and texture reference.
        ACTION: Re-skin the original room's content with the new theme. Be extremely conservative. The goal is a perfect blend of original structure and new style.`;
    } else if (fidelity > 40) {
        return `TASK: Regenerate the 'transformed' image to be more faithful to the 'original room'.

        PRIORITY: Reintroduce key furniture and objects from the 'original room' back into the scene.
        STYLE: Maintain the overall theme and color palette of the 'transformed image'.
        ACTION: Blend the reintroduced original elements seamlessly into the transformed environment, adapting their materials and lighting to fit naturally.`;
    } else {
        return `CREATIVE TASK: Regenerate the 'transformed' image with high creativity, using the 'original room' as a loose structural reference.

        PRIORITY: The theme and style of the 'transformed image' are most important.
        STYLE: Feel free to creatively reinterpret the furniture and layout from the 'original room' to better fit the transformed theme.
        ACTION: Create a new, imaginative version that is inspired by both inputs but favors the artistic style of the transformed version.`;
    }
};

export const regenerateWithFidelity = async (originalImage: ImageFile, transformedImage: ImageFile, fidelity: number): Promise<ServiceResponse<ImageFile>> => {
  try {
    const prompt = getFidelityPrompt(fidelity);

    const response: GenerateContentResponse = await retry(() => ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: { parts: [
        { // Original Image (The reference)
          inlineData: {
            data: originalImage.base64.split(',')[1],
            mimeType: originalImage.mimeType,
          },
        },
        { // Transformed Image (The one to fix/re-interpret)
          inlineData: {
            data: transformedImage.base64.split(',')[1],
            mimeType: transformedImage.mimeType,
          },
        },
        { text: prompt },
      ]},
      config: {
        responseModalities: [Modality.IMAGE],
      },
    }));

    const regeneratedImage = processImageResponse(response, transformedImage.name, `fidelity-${fidelity}`);
    return { data: regeneratedImage, error: null };
  } catch (error) {
    return { data: null, error: formatError(error, 'regenerating with fidelity') };
  }
};

export const identifyObject = async (image: ImageFile): Promise<ServiceResponse<string>> => {
    try {
        const prompt = "Briefly identify the object in this image. Provide a short, descriptive name suitable for a filename (e.g., 'plush_puppet', 'blue_ceramic_mug'). Respond with only the name.";
        
        const response: GenerateContentResponse = await retry(() => ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: { parts: [
                { inlineData: { data: image.base64.split(',')[1], mimeType: image.mimeType } },
                { text: prompt }
            ]},
        }));
        
        const objectName = response.text.trim();
        
        if (!objectName) {
            throw new Error("Model did not return an object name.");
        }
        
        // Sanitize the name for a filename
        const sanitizedName = objectName
            .toLowerCase()
            .replace(/\s+/g, '_') // replace spaces with underscores
            .replace(/[^a-z0-9_-]/g, '') // remove non-alphanumeric characters except underscore, hyphen
            .substring(0, 50); // limit length

        return { data: sanitizedName, error: null };

    } catch (error) {
        return { data: null, error: formatError(error, 'object identification') };
    }
};

export const extractObjectFromImage = async (image: ImageFile, promptText?: string): Promise<ServiceResponse<ImageFile>> => {
    try {
      const basePrompt = `TASK: Isolate, Enhance, and Extract the primary object from this image.

      GOAL: Create a high-quality, product-style photograph of the main subject.
      
      CRITICAL INSTRUCTIONS:
      1.  **IDENTIFY & ISOLATE:** Accurately identify the single most prominent object in the image. Isolate this object completely from its background and any other elements (like hands, people, etc.).
      2.  **TRANSPARENT BACKGROUND:** The output image MUST have a transparent background.
      3.  **ENHANCE & UPSCALE:** Significantly improve the object's resolution, clarity, and lighting. It should look like it was shot in a professional studio.
      4.  **OPTIMAL ORIENTATION:** Re-orient the object to a standard, aesthetically pleasing angle (e.g., front-on, or a slight 3/4 view) so it is presented clearly. It should be upright.
      5.  **OUTPUT:** The final image must contain ONLY the enhanced object on a transparent background.
      
      EXECUTE.`;
  
      const parts = [
        {
          inlineData: {
            data: image.base64.split(',')[1],
            mimeType: image.mimeType,
          },
        },
        { text: basePrompt },
      ];
      
      if (promptText && promptText.trim()) {
          parts.push({text: `USER HINT: The user specified to look for: "${promptText}"`});
      }
  
      const response: GenerateContentResponse = await retry(() => ai.models.generateContent({
        model: 'gemini-2.5-flash-image',
        contents: { parts },
        config: {
          responseModalities: [Modality.IMAGE],
        },
      }));
  
      const extractedObject = processImageResponse(response, image.name, 'extracted-object');
      
      if (extractedObject.mimeType !== 'image/png') {
          extractedObject.mimeType = 'image/png';
          extractedObject.base64 = extractedObject.base64.replace(/^data:image\/[a-z]+;base64,/, 'data:image/png;base64,');
          extractedObject.name = extractedObject.name.replace(/\.[^/.]+$/, ".png");
      }
  
      // Identify the object to get a better name
      const identificationResult = await identifyObject(extractedObject);
      
      if (identificationResult.data && identificationResult.data.length > 0) {
          extractedObject.name = `${identificationResult.data}.png`;
      } else {
          // Fallback to a generic naming scheme if identification fails
          console.warn("Object identification failed:", identificationResult.error);
          const originalFileName = image.name.split('.')[0] || 'image';
          extractedObject.name = `${originalFileName}-extracted-object.png`;
      }

      return { data: extractedObject, error: null };
    } catch (error) {
      return { data: null, error: formatError(error, 'object extraction') };
    }
  };

export const getObjectReimaginationSuggestions = async (objectName: string, environmentTheme?: string): Promise<ServiceResponse<string[]>> => {
    try {
        let prompt: string;

        if (environmentTheme && environmentTheme.trim()) {
            prompt = `You are a creative assistant. The user has an image of a "${objectName}" and wants to place it in an environment with the theme: "${environmentTheme}". Generate 5 short, creative style suggestions for how to visually reimagine the object so it FITS PERFECTLY within that environment. The suggestions should be stylistic themes or materials that match the theme.

            Example for object 'mug' and theme 'Enchanted Forest': "Carved from a glowing mushroom", "Made of ancient, mossy stone", "Gnarled wood with vine handle", "Crystal clear with captured fireflies", "Looks like a strange, magical fruit".

            Respond with ONLY a valid JSON array of 5 unique strings. Example: ["suggestion 1", "suggestion 2", "suggestion 3", "suggestion 4", "suggestion 5"]`;
        } else {
            prompt = `You are a creative assistant. The user has an image of a "${objectName}". Generate 5 short, creative style suggestions for how to visually reimagine it. The suggestions should be stylistic themes or materials.
            
            Examples for a 'mug': "Made of crystal", "Carved from wood", "Ancient stone relic", "Covered in moss", "Steampunk design".
            Examples for a 'toy robot': "Retro tin toy style", "Futuristic chrome finish", "Organic, vine-covered", "Built from LEGO bricks", "Graffiti art style".

            Respond with ONLY a valid JSON array of 5 unique strings. Example: ["suggestion 1", "suggestion 2", "suggestion 3", "suggestion 4", "suggestion 5"]`;
        }

        const response: GenerateContentResponse = await retry(() => ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: { parts: [{ text: prompt }] },
            config: {
                responseMimeType: 'application/json',
                responseSchema: {
                    type: Type.ARRAY,
                    items: { type: Type.STRING }
                }
            }
        }));
        
        const jsonString = response.text;
        const result = JSON.parse(jsonString);
        
        if (Array.isArray(result) && result.length > 0 && result.every(item => typeof item === 'string')) {
            return { data: result.slice(0, 5), error: null }; // Ensure max 5
        } else {
            console.error("Invalid suggestion format received from model:", result);
            return { data: null, error: "Received invalid format for suggestions." };
        }

    } catch (error) {
        return { data: null, error: formatError(error, 'getting object reimagine suggestions') };
    }
};

export const reimagineObject = async (objectImage: ImageFile, prompt: string): Promise<ServiceResponse<ImageFile>> => {
    try {
      const basePrompt = `TASK: Stylistic Reimagination of an Isolated Object.

      INPUT: An image of an object with a transparent background.
      
      GOAL: Redraw the object according to the user's theme, while preserving its exact shape and transparency.
      
      CRITICAL INSTRUCTIONS:
      1.  **PRESERVE SILHOUETTE:** The output image's non-transparent pixels MUST perfectly match the shape of the input object. Do not change its form or outline.
      2.  **MAINTAIN TRANSPARENCY:** The background of the output image MUST be transparent.
      3.  **APPLY THEME:** Apply the following theme to the object's texture, material, and appearance: "${prompt}".
      4.  **OUTPUT:** The final image must be ONLY the reimagined object on a transparent background.
      
      EXECUTE.`;
  
      const response: GenerateContentResponse = await retry(() => ai.models.generateContent({
        model: 'gemini-2.5-flash-image',
        contents: { parts: [
          { inlineData: { data: objectImage.base64.split(',')[1], mimeType: objectImage.mimeType } },
          { text: basePrompt }
        ]},
        config: {
          responseModalities: [Modality.IMAGE],
        },
      }));
  
      const reimaginedObject = processImageResponse(response, objectImage.name, 'reimagined');
      
      // Ensure output is PNG for transparency
      if (reimaginedObject.mimeType !== 'image/png') {
        reimaginedObject.mimeType = 'image/png';
        reimaginedObject.base64 = reimaginedObject.base64.replace(/^data:image\/[a-z]+;base64,/, 'data:image/png;base64,');
        reimaginedObject.name = reimaginedObject.name.replace(/\.[^/.]+$/, ".png");
      }
  
      // Identify the reimagined object to get a better name
      const identificationResult = await identifyObject(reimaginedObject);
      
      if (identificationResult.data && identificationResult.data.length > 0) {
          reimaginedObject.name = `${identificationResult.data}.png`;
      } else {
          console.warn("Reimagined object identification failed:", identificationResult.error);
          // Fallback to a name based on the prompt
          const promptPart = prompt.trim().toLowerCase().replace(/\s+/g, '_').replace(/[^a-z0-9_-]/g, '').substring(0, 20);
          reimaginedObject.name = `${promptPart}_reimagined.png`;
      }

      return { data: reimaginedObject, error: null };
    } catch (error) {
      return { data: null, error: formatError(error, 'reimagining object') };
    }
};

export const blendObjectIntoScene = async (
  environmentImage: ImageFile,
  objectImage: ImageFile,
  transform: ObjectTransform
): Promise<ServiceResponse<ImageFile>> => {
  try {
    // Step 1: Create a composite image on a canvas
    const compositeCanvas = document.createElement('canvas');
    const compositeCtx = compositeCanvas.getContext('2d');
    if (!compositeCtx) {
      throw new Error("Could not create canvas context for blending.");
    }

    const envImg = await new Promise<HTMLImageElement>((resolve, reject) => {
        const img = new Image();
        img.onload = () => resolve(img);
        img.onerror = reject;
        img.src = environmentImage.base64;
    });

    const objImg = await new Promise<HTMLImageElement>((resolve, reject) => {
        const img = new Image();
        img.onload = () => resolve(img);
        img.onerror = reject;
        img.src = objectImage.base64;
    });

    // Set canvas to environment size
    compositeCanvas.width = envImg.width;
    compositeCanvas.height = envImg.height;

    // Draw environment
    compositeCtx.drawImage(envImg, 0, 0);

    // Draw object with transform
    compositeCtx.save();
    compositeCtx.translate(transform.x + transform.width / 2, transform.y + transform.height / 2);
    compositeCtx.rotate(transform.rotation * Math.PI / 180);
    compositeCtx.drawImage(objImg, -transform.width / 2, -transform.height / 2, transform.width, transform.height);
    compositeCtx.restore();
    
    const compositeBase64 = compositeCanvas.toDataURL('image/jpeg');
    const compositeMimeType = 'image/jpeg';

    // Step 2: Send to Gemini for blending
    const prompt = `This image is a composite of a background scene and a foreground object that has been placed on top. Your task is to seamlessly blend the foreground object into the background scene. Make the object look like it naturally belongs there by:
1.  **Adding realistic shadows:** The shadows should match the direction, softness, and color of the existing light sources in the scene.
2.  **Adjusting lighting:** The object's lighting and highlights should be consistent with the environment.
3.  **Creating reflections/interactions:** If the object is on a reflective surface, add appropriate reflections. If it's on a soft surface like grass or carpet, make it look slightly settled in.
4.  **Maintaining integrity:** CRITICAL: Do NOT change the object's position, size, rotation, or design. Do NOT change the background scene. Your ONLY job is to blend the pre-placed object.`;

    const response: GenerateContentResponse = await retry(() => ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: { parts: [
        {
          inlineData: {
            data: compositeBase64.split(',')[1],
            mimeType: compositeMimeType,
          },
        },
        { text: prompt },
      ]},
      config: {
        responseModalities: [Modality.IMAGE],
      },
    }));

    const blendedImage = processImageResponse(response, environmentImage.name, 'composed');
    return { data: blendedImage, error: null };

  } catch (error) {
    return { data: null, error: formatError(error, 'blending object into scene') };
  }
};

export const generateObjectFromPrompt = async (prompt: string): Promise<ServiceResponse<ImageFile>> => {
  try {
    const generationPrompt = `
      TASK: Generate a high-quality, photorealistic image of an object based on the user's description.
      
      USER DESCRIPTION: "${prompt}"

      CRITICAL INSTRUCTIONS:
      1.  **ISOLATION:** The object MUST be the only thing in the image.
      2.  **TRANSPARENT BACKGROUND:** The output image MUST have a transparent background. This is non-negotiable.
      3.  **QUALITY:** The object should be well-lit, high-resolution, and appear as if it were shot in a professional photo studio.
      4.  **ORIENTATION:** Present the object in a standard, clear, and aesthetically pleasing orientation (e.g., front-on or a slight 3/4 view).
      5.  **OUTPUT:** The final image must contain ONLY the generated object on a transparent background.
      
      EXECUTE.
    `;

    const response: GenerateContentResponse = await retry(() => ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: { parts: [{ text: generationPrompt }] },
      config: {
        responseModalities: [Modality.IMAGE],
      },
    }));

    const generatedObject = processImageResponse(response, 'generated-object', 'generated');

    if (generatedObject.mimeType !== 'image/png') {
        generatedObject.mimeType = 'image/png';
        generatedObject.base64 = generatedObject.base64.replace(/^data:image\/[a-z]+;base64,/, 'data:image/png;base64,');
    }

    // Use the prompt to create a filename
    const sanitizedName = prompt
        .toLowerCase()
        .replace(/\s+/g, '_')
        .replace(/[^a-z0-9_-]/g, '')
        .substring(0, 50) || 'generated_object';

    generatedObject.name = `${sanitizedName}.png`;

    return { data: generatedObject, error: null };
  } catch (error) {
    return { data: null, error: formatError(error, 'generating object from prompt') };
  }
};
